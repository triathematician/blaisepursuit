#summary This page describes the structure used to implement the pursuit/evasion simulations.
#labels Featured

= Running a simulation =
The class `Simulation` handles the primary task of running a simulation. The primary method to call is the `run()` method, which has three main steps: a `preRun()` step, an `iterate()` step (called multiple times), and a `postRun()` step. A special method `isFinished()` is used to determine when the simulation concludes. I also have built in a special exception, `SimulationTerminatedException` Here is the source code for the `run()` method:

{{{
public final void run() {
    preRun();
    try {
        while (!isFinished()) {
            iterate();
        }
    } catch (SimulationTerminatedException ex) {
        System.out.println("Victory achieved by one of the teams! ("+ex.explanation+")");
    }
    postRun();
}
}}}

Some comments on this:
  * The `preRun()` method currently calls the `initStateVariables()` method, which sets up the simulation for running.
  * The `isFinished()` method describes the default end-of-time for the simulation... currently set up to terminate after a fixed period of time.
  * The `iterate()` method encodes the main iteration structure, and is described further below.
  * The `postRun()` method is called after the simulation has ended. Currently, nothing of interest is done here.
  * The `SimulationTerminatedException` may be called within the `iterate()` method, and allows intermediate methods to also terminate the simulation, escaping out of the iteration phase (e.g. a special victory condition).

= Composite Structure of Simulations =

Simulations are comprised of `SimulationComponent`s, which might be agents, obstacles, or teams of agents.

= Iteration Structure Steps (new version) =

Generally speaking, pursuit/evasion algorithms between multiple players contain three steps: MTT (multiple target tracking), PEA (pursuer-evader assignment), and PP (path planning).

In the new version, these are implemented within the `Simulation.iterate()` method. Here is the detailed description of that method:
   # *DISTANCE CALCULATION*
    * Recalculate current time `curTime` and distance cache table `dt`. The distance cache is used for purposes of speed to store the true distances between each pair of agents.
   # *CAPTURE CHECKING*
    * Call `handleMajorEvents(dt, curTime)`. There should handle major events like one team capturing another.
   # *VICTORY CHECKING*
    * Check to see if any of the simulation's components have achieved victory, by calling `checkVictory(dt, curTime)`. This method may throw a `SimulationTerminationException`, causing the simulation to finish early.
     * Teams call `VictoryCondition.hasBeenMet(dt,curTime)` (if they have a victory condition) to see whether victory has been achieved.
   # *DATA LOGGING*
    * Notify any loggers to store the current status of the simulation... the method is `fireIterationEvent(curTime)`, and interested listeners will be passed both the distance table and the time.
   # *MULTIPLE TARGET TRACKING (MTT)*: a combination of communicated locations and sensing locations
    * Components process any incoming communications events, `processIncomingCommEents(curTime)`.
    * Components gather data using their sensors, `gatherSensoryData(dt)`. The sensors are responsible for using the information in the distance table to return the agents that are "visible" to them.
     * Agents and teams call the `Sensor.findAgents(DistanceCache, position, velocity)` method to populate their table of visible opponents.
    * Components consolidate comm information and sensory information in the `developPointOfView()` method.
     * Agents populate their point-of-view table describing their beliefs about opponent locations.
   # *PURSUER-EVADER ASSIGNMENT (PEA)*: using a tasking system whereby teams or agents create tasks for one or more other agents
    * Components generate tasks, which may be for themselves or for fellow players, in the `generateTasks(dt)` method.
     * Calls the `TaskGenerator.generateGiven(DistanceCache, owner, opponents, teammates)` method to generate tasks based upon the current point-of-view.
   # *PATH-PLANNING (PP)*
    * Components set their _control variables_ in the `setControlVariables(curTime, timePerStep)` method.
     * Selection of desired task to follow in the `TaskPrioritizer.chooseTask(tasks)` method... this may return a task that represents a hybrid of multiple tasks.
     * Implementation of that task in the `TaskImplementer.getDirectionFor(task)` method. This is where different strategies, such as leading algorithms, may occur.
    * Components move their positions using the `adjustState(timePerStep)` method, which alters their current position/velocity based upon the control variables.
   # *FINAL COMMUNICATIONS*
    * Components send out communications events in the `sendAllCommEvents(curTime)` method. The intention here is e.g. for them to communicate about the locations of agents they see to their teammates.


= Iteration Structure Steps (old version) =
In the old version, these were implemented in the steps of the main iteration of the pursuit simulation, the `Simulation.iterate(double time)` method.

 # *DISTANCE COMPUTATION*.
  * Recompute distances between all players (stored in *`DistanceTable`* class)
 # *CAPTURE CHECK*.
  * Check for any captures that may have occurred (as registered by any team's *`CaptureCondition`* distance threshold criterion). Depending on the `removal` setting, remove one or both of the pursuer and evader. The closest players are removed first.
   * _`CaptureCondition.check(DistanceTable dt, SimulationLog log, CaptureMap cap, double time)`_
  * Create a *`SignificantEvent`* and mark the capture point on the playing field.
   * _`SimulationLog.logCaptureEvent(Team owner, Agent first, Team target, Agent second, String string, DistanceTable dt, double time)`_
  * Store the capturing players and the capture time, for later use in computing metrics for the teams or partial teams.
   * _`CaptureMap.logCapture(Agent agent, Agent target, double time)`_
 # *VICTORY CHECK*.
  * Check for any "victory" that has occurred (as registered by a team's *`VictoryCondition`* class).
   * _`int VictoryCondition.check(DistanceTable dt, SimulationLog log, CaptureMap cap, double time)`_
  * The check may return "victory", "defeat", or "neither", obtained by comparing the valuation (from the parent class) to the given threshold.
   * _`Valuation.getValue(DistanceTable dt, CaptureMap cap)`_
  * If the check shows that the game should end, whether in victory or defeat, log an event to note this.
   * _`SimulationLog.logEvent(Team owner, Agent first, Team target, Agent second, String string, double time)`._
 # *MULTIPLE TARGET TRACKING (MTT)*.
  * Active players _sense_ their environment, by adding all agents in their sensory radius to their `Vector<Agent> pov`.
   * _`Team.gatherSensoryData(DistanceTable dt)`_
   * _`Agent.gatherSensoryData(DistanceTable dt)`_
  * Active players _communicate_ with teammates in their communications radius about what they see, by adding all sensed agents to their teammates `Vector<Agent> commpov`.
   * _`Team.communicateSensoryData(DistanceTable dt)`_
   * _`Agent.generateSensoryEvents(Team team,DistanceTable dist)`_
   * _`Agent.acceptSensoryEvent(Collection<Agent> agents)`_
  * Active players _fuse_ their own perceptions with those communicated by others to form a belief about what's really out there, currently by simply adding all agents in `commpov` to those in `pov`.
   * _`Team.fuseAgentPOV()`_
   * _`Agent.fusePOV()`_
 # *TASKING / PURSUER-EVADER ASSIGNMENT (PEA)*.
  * Each team handles the assignment problem by generating _control tasks_ using the "control agent" `taskings` and having each active player also generate _autonomous tasks_. Players have collections of *`Tasking`* objects, each of which wraps up a *`TaskGenerator`* object that is responsible for assigning agents *`Task`*s based on the current field of play. Each *`Task`* contains a `priority` that is later used by the agent to decide the ultimate action.
   * _`Team.assignTasks(DistanceTable dt)`_
   * _`Agent.generateTasks(Team team, DistanceTable dt, double priority)`_
   * _`TaskGenerator.generate(Collection<Agent> team, DistanceTable dt, double priority)`_
   * _`new Task(TaskGenerator source, V2 target, int type, double priority)`_
   * _`Agent.assign(Task t)`_
 # *TASK FUSION / PATH PLANNING (PP)*.
  * The active players plan their paths based on the assigned tasks. Each *`Task`* leads to a desired direction of travel (a *`V2`*), with the conversion happening within a *`Behavior`* class. So _behaviors_ correspond to leading strategies, search strategies, etc.
   * _`Team.planPaths(double time, double stepTime)`_
   * _`Agent.planPath(double time, double stepTime)`_
   * _`R2 TaskFusion.getVector(Agent agent, Vector<Task> tasks, double time)`_
   * _`R2 Behavior.direction(Agent self, V2 target, double time)`_
 # *MOVEMENT*.
  * Active agents change their locations based on previously assigned directions.
   * _`Team.move(double stepTime)`_
   * _`Agent.move(double stepTime)`_